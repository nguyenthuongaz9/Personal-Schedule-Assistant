import re
import json
from datetime import datetime, timedelta
from typing import Dict, Any, Optional
import requests
import logging

logger = logging.getLogger(__name__)

class VietnameseNLProcessor:
    def __init__(self, config, db_manager):
        self.config = config
        self.db = db_manager
        self.setup_patterns()
    
    def setup_patterns(self):
        """Thi·∫øt l·∫≠p patterns cho ti·∫øng Vi·ªát"""
        self.intent_patterns = {
            'create_schedule': [
                r'(ƒë·∫∑t|l·∫≠p|t·∫°o)\s+(l·ªãch|cu·ªôc h·ªçp|s·ª± ki·ªán)',
                r'(h·∫πn|schedule)\s+(.*)',
                r'(mai|ng√†y mai|h√¥m nay|chi·ªÅu nay|s√°ng nay)\s+(.*)\s+l√∫c\s+(\d+)',
                r't·∫°o l·ªãch',
                r'th√™m l·ªãch'
            ],
            'query_schedule': [
                r'(xem|ki·ªÉm tra|tra c·ª©u)\s+(l·ªãch|l·ªãch tr√¨nh)',
                r'(c√≥|l·ªãch)\s+g√¨\s+(mai|h√¥m nay|tu·∫ßn n√†y)',
                r'l·ªãch tr√¨nh\s+(.*)',
                r'xem l·ªãch',
                r'h√¥m nay c√≥ g√¨'
            ],
            'update_schedule': [
                r'(thay ƒë·ªïi|ch·ªânh s·ª≠a|c·∫≠p nh·∫≠t|d·ªùi)\s+(l·ªãch|cu·ªôc h·ªçp)',
                r'ho√£n\s+(.*)',
                r'ƒë·ªïi\s+gi·ªù\s+(.*)'
            ],
            'delete_schedule': [
                r'(h·ªßy|x√≥a|xo√°)\s+(l·ªãch|cu·ªôc h·∫πn)',
                r'x√≥a\s+(.*)',
                r'h·ªßy b·ªè\s+(.*)'
            ]
        }
    
    def detect_intent(self, text: str) -> Dict[str, Any]:
        """Ph√°t hi·ªán intent t·ª´ c√¢u ti·∫øng Vi·ªát - LU√îN G·ªåI OLLAMA ƒê·ªÇ TEST"""
        text = text.lower().strip()
        
        logger.info(f"üîç Analyzing text: '{text}'")
        
        # T·∫†M TH·ªúI COMMENT PATTERN MATCHING ƒê·ªÇ TEST OLLAMA
        # # Ki·ªÉm tra pattern c∆° b·∫£n tr∆∞·ªõc
        # for intent, patterns in self.intent_patterns.items():
        #     for pattern in patterns:
        #         if re.search(pattern, text):
        #             logger.info(f"Detected intent '{intent}' using pattern matching")
        #             return self._enhance_with_basic_analysis(text, intent)
        
        # LU√îN G·ªåI OLLAMA ƒê·ªÇ TEST
        logger.info("üöÄ Bypassing pattern matching, forcing Ollama call...")
        return self._analyze_with_ollama(text)
    
    def _enhance_with_basic_analysis(self, text: str, intent: str) -> Dict[str, Any]:
        """Ph√¢n t√≠ch c∆° b·∫£n v·ªõi pattern matching"""
        text_lower = text.lower()
        
        # Extract th·ªùi gian c∆° b·∫£n
        time_info = self.extract_time_info(text)
        
        # Extract ti√™u ƒë·ªÅ
        title = self._extract_title(text, intent)
        
        return {
            'intent': intent,
            'title': title,
            'description': '',
            'datetime': time_info['datetime'],
            'duration_minutes': 60,
            'priority': 'medium',
            'confidence': 0.8,
            'method': 'pattern'
        }
    
    def _extract_title(self, text: str, intent: str) -> str:
        """Tr√≠ch xu·∫•t ti√™u ƒë·ªÅ t·ª´ c√¢u"""
        if intent == 'create_schedule':
            # T√¨m ph·∫ßn m√¥ t·∫£ sau t·ª´ kh√≥a
            patterns = [
                r'ƒë·∫∑t l·ªãch\s+(.+)',
                r't·∫°o l·ªãch\s+(.+)', 
                r'l·∫≠p l·ªãch\s+(.+)',
                r'h·∫πn\s+(.+)'
            ]
            for pattern in patterns:
                match = re.search(pattern, text.lower())
                if match:
                    extracted = match.group(1).strip()
                    # Lo·∫°i b·ªè ph·∫ßn th·ªùi gian n·∫øu c√≥
                    extracted = re.sub(r'(l√∫c\s+\d+|s√°ng|chi·ªÅu|t·ªëi|mai|h√¥m nay)', '', extracted).strip()
                    return extracted if extracted else "S·ª± ki·ªán m·ªõi"
        
        return "S·ª± ki·ªán m·ªõi"
    
    def _analyze_with_ollama(self, text: str) -> Dict[str, Any]:
        """Ph√¢n t√≠ch c√¢u ph·ª©c t·∫°p v·ªõi Ollama v·ªõi timeout 5 ph√∫t"""
        prompt = self._build_analysis_prompt(text)
        
        logger.info("=" * 80)
        logger.info("ü§ñ OLLAMA REQUEST START")
        logger.info(f"üìù Input text: '{text}'")
        logger.info(f"üîó Ollama URL: {self.config.OLLAMA_URL}")
        logger.info(f"üéØ Model: {self.config.OLLAMA_MODEL}")
        logger.info("üì§ Sending request to Ollama...")
        
        try:
            # TIMEOUT 5 PH√öT (300 gi√¢y) cho deepseek-r1
            timeout = 300
            
            logger.info(f"‚è∞ Timeout setting: {timeout} seconds")
            
            start_time = datetime.now()
            
            response = requests.post(
                self.config.OLLAMA_URL,
                json={
                    "model": self.config.OLLAMA_MODEL,
                    "prompt": prompt,
                    "stream": False,
                    "options": {
                        "temperature": 0.1,
                        "top_p": 0.9,
                        "num_predict": 500,
                        "top_k": 40
                    }
                },
                timeout=timeout
            )
            
            processing_time = (datetime.now() - start_time).total_seconds()
            logger.info(f"‚úÖ Ollama response received in {processing_time:.2f} seconds")
            logger.info(f"üìä Response status: {response.status_code}")
            
            if response.status_code == 200:
                result = response.json()
                response_text = result.get('response', '').strip()
                
                logger.info("üìÑ RAW OLLAMA RESPONSE:")
                logger.info("-" * 40)
                logger.info(response_text)
                logger.info("-" * 40)
                logger.info(f"üìè Response length: {len(response_text)} characters")
                
                if response_text:
                    parsed_result = self._parse_ollama_response(response_text, text)
                    logger.info("üéØ PARSED RESULT:")
                    logger.info(json.dumps(parsed_result, indent=2, ensure_ascii=False))
                    logger.info("ü§ñ OLLAMA REQUEST COMPLETED")
                    logger.info("=" * 80)
                    return parsed_result
                else:
                    logger.warning("‚ùå Ollama returned empty response")
                    logger.info("ü§ñ OLLAMA REQUEST FAILED - EMPTY RESPONSE")
                    logger.info("=" * 80)
                    return self._fallback_analysis(text)
            else:
                logger.error(f"‚ùå Ollama API error: {response.status_code}")
                logger.error(f"Error details: {response.text}")
                logger.info("ü§ñ OLLAMA REQUEST FAILED - API ERROR")
                logger.info("=" * 80)
                return self._fallback_analysis(text)
                
        except requests.exceptions.Timeout:
            logger.error(f"‚ùå Ollama request timeout after {timeout} seconds (5 minutes)")
            logger.info("ü§ñ OLLAMA REQUEST FAILED - TIMEOUT")
            logger.info("=" * 80)
            return self._fallback_analysis(text)
        except requests.exceptions.ConnectionError:
            logger.error("‚ùå Cannot connect to Ollama - is it running?")
            logger.info("ü§ñ OLLAMA REQUEST FAILED - CONNECTION ERROR")
            logger.info("=" * 80)
            return self._fallback_analysis(text)
        except Exception as e:
            logger.error(f"‚ùå Ollama connection error: {e}")
            logger.info("ü§ñ OLLAMA REQUEST FAILED - UNKNOWN ERROR")
            logger.info("=" * 80)
            return self._fallback_analysis(text)
    
    def _build_analysis_prompt(self, text: str) -> str:
        """X√¢y d·ª±ng prompt cho Ollama v·ªõi context r√µ r√†ng"""
        current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        return f"""
B·∫°n l√† tr·ª£ l√Ω AI ph√¢n t√≠ch c√¢u ti·∫øng Vi·ªát v·ªÅ l·ªãch tr√¨nh.

C√ÇU: "{text}"
TH·ªúI GIAN HI·ªÜN T·∫†I: {current_time}

PH√ÇN T√çCH:
1. M·ª§C ƒê√çCH (intent):
   - "schedule": t·∫°o l·ªãch m·ªõi (ƒë·∫∑t l·ªãch, t·∫°o l·ªãch, l·∫≠p l·ªãch, h·∫πn)
   - "query": xem l·ªãch (xem l·ªãch, ki·ªÉm tra l·ªãch, l·ªãch tr√¨nh)
   - "update": s·ª≠a l·ªãch (thay ƒë·ªïi, ch·ªânh s·ª≠a, ho√£n)
   - "delete": x√≥a l·ªãch (h·ªßy, x√≥a)
   - "unknown": kh√¥ng x√°c ƒë·ªãnh

2. TH√îNG TIN:
   - title: ti√™u ƒë·ªÅ s·ª± ki·ªán
   - datetime: th·ªùi gian YYYY-MM-DD HH:MM:SS
   - duration_minutes: th·ªùi l∆∞·ª£ng ph√∫t
   - priority: ƒë·ªô ∆∞u ti√™n (low, medium, high)

3. TH·ªúI GIAN TI·∫æNG VI·ªÜT:
   - "mai" = ng√†y mai
   - "h√¥m nay" = h√¥m nay
   - "s√°ng" = 7:00-11:00
   - "chi·ªÅu" = 13:00-17:00  
   - "t·ªëi" = 19:00-22:00

K·∫æT QU·∫¢ (CH·ªà JSON):
{{
    "intent": "schedule",
    "title": "h·ªçp",
    "description": "",
    "datetime": "2024-01-02 09:00:00",
    "duration_minutes": 60,
    "priority": "medium",
    "confidence": 0.9,
    "method": "ollama"
}}

CH·ªà TR·∫¢ V·ªÄ JSON, KH√îNG GI·∫¢I TH√çCH.
"""
    
    def _parse_ollama_response(self, response: str, original_text: str) -> Dict[str, Any]:
        """Ph√¢n t√≠ch k·∫øt qu·∫£ t·ª´ Ollama"""
        try:
            logger.info("üîç Parsing Ollama response...")
            
            # L√†m s·∫°ch response
            cleaned_response = re.sub(r'```json\s*|\s*```', '', response).strip()
            logger.info(f"üßπ Cleaned response: '{cleaned_response}'")
            
            # T√¨m JSON trong response
            json_match = re.search(r'\{[^{}]*\{[^{}]*\}[^{}]*\}|\{[^{}]*\}', cleaned_response, re.DOTALL)
            if json_match:
                json_str = json_match.group()
                logger.info(f"üì¶ Found JSON: {json_str}")
                data = json.loads(json_str)
                logger.info(f"‚úÖ Successfully parsed JSON")
                return data
            else:
                logger.warning(f"‚ùå No JSON found in Ollama response")
                logger.info(f"üìÑ Full response was: {cleaned_response}")
                return self._fallback_analysis(original_text)
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå JSON decode error: {e}")
            logger.error(f"üìÑ Response that failed: {response}")
            return self._fallback_analysis(original_text)
        except Exception as e:
            logger.error(f"‚ùå Error parsing Ollama response: {e}")
            return self._fallback_analysis(original_text)
    
    def _fallback_analysis(self, text: str) -> Dict[str, Any]:
        """Ph√¢n t√≠ch fallback khi Ollama kh√¥ng ho·∫°t ƒë·ªông"""
        logger.info("üîÑ Using fallback analysis")
        
        text_lower = text.lower()
        
        if any(word in text_lower for word in ['ƒë·∫∑t l·ªãch', 't·∫°o l·ªãch', 'l·∫≠p l·ªãch', 'h·∫πn']):
            intent = 'schedule'
            confidence = 0.7
        elif any(word in text_lower for word in ['xem l·ªãch', 'ki·ªÉm tra l·ªãch', 'l·ªãch tr√¨nh', 'c√≥ g√¨']):
            intent = 'query'
            confidence = 0.8
        elif any(word in text_lower for word in ['thay ƒë·ªïi', 'ch·ªânh s·ª≠a', 'c·∫≠p nh·∫≠t', 'ho√£n']):
            intent = 'update'
            confidence = 0.6
        elif any(word in text_lower for word in ['h·ªßy', 'x√≥a', 'xo√°']):
            intent = 'delete'
            confidence = 0.7
        else:
            intent = 'unknown'
            confidence = 0.3
        
        time_info = self.extract_time_info(text)
        
        result = {
            'intent': intent,
            'title': self._extract_title(text, intent),
            'description': '',
            'datetime': time_info['datetime'],
            'duration_minutes': 60,
            'priority': 'medium',
            'confidence': confidence,
            'method': 'fallback'
        }
        
        logger.info(f"üîÑ Fallback result: {result}")
        return result
    
    def extract_time_info(self, text: str) -> Dict[str, Any]:
        """Tr√≠ch xu·∫•t th√¥ng tin th·ªùi gian t·ª´ c√¢u ti·∫øng Vi·ªát"""
        now = datetime.now()
        text_lower = text.lower()
        
        # X·ª≠ l√Ω ng√†y
        if 'mai' in text_lower or 'ng√†y mai' in text_lower:
            target_date = now + timedelta(days=1)
        elif 'h√¥m nay' in text_lower:
            target_date = now
        elif 'h√¥m qua' in text_lower:
            target_date = now - timedelta(days=1)
        else:
            target_date = now
        
        # X·ª≠ l√Ω gi·ªù
        hour = 9  # M·∫∑c ƒë·ªãnh 9h
        minute = 0
        
        # T√¨m gi·ªù trong c√¢u
        time_match = re.search(r'(\d+)\s*gi·ªù\s*(\d*)|l√∫c\s*(\d+)', text_lower)
        if time_match:
            groups = time_match.groups()
            hour_str = next((g for g in groups if g), None)
            if hour_str:
                hour = int(hour_str)
        
        # T√¨m ph√∫t
        minute_match = re.search(r'(\d+)\s*ph√∫t', text_lower)
        if minute_match:
            minute = int(minute_match.group(1))
        
        # X·ª≠ l√Ω s√°ng/chi·ªÅu/t·ªëi
        if 'chi·ªÅu' in text_lower or 't·ªëi' in text_lower:
            if hour < 12:
                hour += 12
        elif 's√°ng' in text_lower and hour == 12:
            hour = 0
        
        # ƒê·∫£m b·∫£o gi·ªù h·ª£p l·ªá
        hour = max(0, min(23, hour))
        minute = max(0, min(59, minute))
        
        target_datetime = target_date.replace(
            hour=hour, minute=minute, second=0, microsecond=0
        )
        
        return {
            'datetime': target_datetime.strftime('%Y-%m-%d %H:%M:%S'),
            'date': target_date.strftime('%Y-%m-%d'),
            'time': f"{hour:02d}:{minute:02d}"
        }
